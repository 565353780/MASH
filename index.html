<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>MASH: Masked Anchored SpHerical Distances for 3D Shape Representation and Generation</title>
    <style>
        /* 全局样式 */
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
        }

        body {
            background: white;
            color: #333;
            line-height: 1.6;
        }

        .container {
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }

        /* 标题样式 */
        header {
            text-align: center;
            padding: 60px 0;
            background: white;
            color: #333;
            margin-bottom: 40px;
            border-radius: 0 0 20px 20px;
            box-shadow: 0 4px 20px rgba(0, 0, 0, 0.1);
        }

        h1 {
            font-size: 2.8rem;
            margin-bottom: 20px;
            letter-spacing: 2px;
        }

        .authors {
            font-size: 1.2rem;
            margin-bottom: 30px;
            opacity: 0.9;
            text-align: center;
        }

        .author-name {
            font-weight: 500;
            margin-right: 5px;
        }
        
        .author-name a {
            color: #0078D7;
            text-decoration: none;
        }
        
        .author-name a:hover {
            text-decoration: underline;
        }

        .affiliation-list {
            text-align: center;
            margin-top: 5px;
            font-size: 1.1rem;
        }

        .affiliation {
            display: inline;
            margin-right: 15px;
            font-size: 0.95rem;
            opacity: 0.9;
        }

        sup {
            font-size: 0.7rem;
            vertical-align: super;
            color: #666;
        }

        .abstract {
            max-width: 1600px;
            margin: 0 auto;
            font-size: 1.1rem;
            line-height: 1.8;
            padding: 20px;
            background-color: white;
            border-radius: 10px;
        }

        /* 内容区域 */
        .content-section {
            margin-bottom: 60px;
        }

        h2 {
            font-size: 2rem;
            margin-bottom: 30px;
            color: #444;
            position: relative;
            padding-bottom: 10px;
        }

        h2::after {
            content: '';
            position: absolute;
            bottom: 0;
            left: 0;
            width: 60px;
            height: 4px;
            background: linear-gradient(to right, #6e8efb, #a777e3);
            border-radius: 2px;
        }

        /* 结果图展示 */
        .results-grid {
            display: grid;
            grid-template-columns: repeat(auto-fill, minmax(300px, 1fr));
            gap: 30px;
            margin-top: 30px;
        }

        .result-item {
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
            transition: transform 0.3s ease, box-shadow 0.3s ease;
        }

        .result-item:hover {
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(0, 0, 0, 0.15);
        }

        .result-image {
            width: 100%;
            height: 200px;
            object-fit: cover;
        }

        .result-content {
            padding: 20px;
        }

        .result-title {
            font-size: 1.2rem;
            margin-bottom: 10px;
            color: #333;
        }

        .result-description {
            color: #666;
            font-size: 0.95rem;
        }

        /* 视频展示 */
        .video-container {
            margin-top: 30px;
            background: white;
            border-radius: 10px;
            overflow: hidden;
            box-shadow: 0 5px 15px rgba(0, 0, 0, 0.1);
        }

        .video-wrapper {
            position: relative;
            padding-bottom: 56.25%;
            /* 16:9 比例 */
            height: 0;
            overflow: hidden;
        }

        .video-wrapper iframe,
        .video-wrapper video {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }

        /* 页脚 */
        footer {
            text-align: center;
            padding: 30px 0;
            margin-top: 60px;
            color: #666;
            font-size: 0.9rem;
        }

        .github-link {
            display: inline-block;
            margin-top: 20px;
            padding: 10px 20px;
            background: #333;
            color: white;
            text-decoration: none;
            border-radius: 5px;
            transition: background 0.3s ease;
        }

        .github-link:hover {
            background: #555;
        }

        /* 动画效果 */
        @keyframes fadeIn {
            from {
                opacity: 0;
                transform: translateY(20px);
            }

            to {
                opacity: 1;
                transform: translateY(0);
            }
        }

        .fade-in {
            animation: fadeIn 0.8s ease forwards;
        }
    </style>
</head>

<body>
    <header class="fade-in">
        <div class="container">
            <h1><span style="color: #333">MASH</span>: <span style="color: #999"><span style="color: #0078D7">M</span>asked <span style="color: #0078D7">A</span>nchored <span style="color: #0078D7">S</span>p<span style="color: #0078D7">H</span>erical</span> <span style="color: #999">Distances</span><br>
            <span style="color: #333">for 3D Shape Representation and Generation</span></h1>
            <div class="authors">
                <p>
                    <span class="author-name"><a href="https://565353780.github.io/">Changhao Li</a><sup>1</sup></span>, 
                    <span class="author-name">Yu Xin<sup>1</sup></span>, 
                    <span class="author-name"><a href="https://xzhou.me/">Xiaowei Zhou</a><sup>2</sup></span>, 
                    <span class="author-name"><a href="https://faculty.runi.ac.il/arik/site/index.asp">Ariel Shamir</a><sup>3</sup></span>, 
                    <span class="author-name"><a href="https://www.cs.sfu.ca/~haoz/">Hao Zhang</a><sup>4</sup></span>, 
                    <span class="author-name"><a href="http://staff.ustc.edu.cn/~lgliu/">Ligang Liu</a><sup>1</sup></span>, 
                    <span class="author-name"><a href="https://csse.szu.edu.cn/staff/ruizhenhu/">Ruizhen Hu</a><sup>5</sup></span>
                </p>
                <div class="affiliation-list">
                    <span class="affiliation"><sup>1</sup>USTC</span>
                    <span class="affiliation"><sup>2</sup>State Key Laboratory of CAD & CG, ZJU</span>
                    <span class="affiliation"><sup>3</sup>Reichman University</span>
                    <span class="affiliation"><sup>4</sup>SFU</span>
                    <span class="affiliation"><sup>5</sup>SZU</span>
                </div>
            </div>
            <!-- 将 Figure 1 移到这里 -->
            <div align="center" style="margin-top: 30px; margin-bottom: 30px; max-width: 880px; margin-left: auto; margin-right: auto;">
                <img src="./images/representative_image.jpg" width="100%" alt="Figure 1">
                <p class="result-description" style="margin-top: 15px; color: #333; width: 100%;">
                    <strong>Figure 1:</strong> MASH represents a 3D shape by fitting a set of Masked Anchored SpHerical distance
                    functions as observed from the perspective of a fixed number of anchor points in 3D space. Left shows an
                    iterative optimization of MASH parameters, from an unoriented point cloud, leading to closer and closer
                    approximations to the ground-truth shape surface. Middle and right show the versatility of MASH in enabling
                    a variety of downstream applications including shape completion, blending, and conditional 3D generation
                    from multi-modal inputs including text prompts, point clouds, and single-view images.
                </p>
            </div>
            
            <div class="abstract">
                <p>
                    We introduce Masked Anchored SpHerical Distances (MASH), a novel multi-view and parametrized
                    representation of 3D shapes. Inspired by multi-view geometry and motivated by the importance of
                    perceptual shape understanding for learning 3D shapes, MASH represents a 3D shape as a collection of
                    observable local surface patches, each defined by a spherical distance function emanating from an
                    anchor point. We further leverage the compactness of spherical harmonics to encode the MASH
                    functions, combined with a generalized view cone with a parameterized base that masks the spatial
                    extent of the spherical function to attain locality. We develop a differentiable optimization
                    algorithm capable of converting any point cloud into a MASH representation accurately approximating
                    ground-truth surfaces with arbitrary geometry and topology. Extensive experiments demonstrate that
                    MASH is versatile for multiple applications including surface reconstruction, shape generation,
                    completion, and blending, achieving superior performance thanks to its unique representation
                    encompassing both implicit and explicit features.
                </p>
            </div>
        </div>
    </header>

    <div class="container fade-in">

        <!-- MASH核心表示方法 -->
        <div class="content-section">
            <h2>MASH Representation</h2>
            <div align="center" style="margin-top: 30px; margin-bottom: 30px;">
                <img src="./images/MASH_representation.png" style="max-width: 880px; width: 100%;" alt="MASH表示方法">
            </div>
            <p class="result-description" style="margin-top: 15px; color: #333;">
                MASH is a set of anchors. Each anchor observes objects along direction <strong><em>v</em></strong> from an spatial point <strong><em>p</em></strong>. It uses spherical harmonic coefficients <strong><em>C</em></strong> to encode distance information along different directions, while utilizing trigonometric basis function coefficients <strong><em>V</em></strong> to generate a view cone that constrains the representation range of the spherical distance functions, thereby accurately representing local surface geometry of the object.
            </p>
        </div>

        <!-- 技术视频展示 -->
        <div class="content-section">
            <h2>Objective function</h2>
            
            <!-- 视频4：目标函数 -->
            <div class="video-container" style="margin-bottom: 30px;">
                <div class="video-wrapper">
                    <video width="100%" height="auto" controls>
                        <source src="./video/4_objective_function.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div style="padding: 15px;">
                    <p class="result-description">
                        We use a differentiable way to calculate the sampled points on surface patches from MASH parameters, which enables us to optimize MASH parameters by minimizing Fitting Error, Coverage Error and Boundary-continuous Error.
                    </p>
                </div>
            </div>
            
            <!-- 视频5：可微分优化 -->
            <h2>Differentiable Optimization</h2>
            <div class="video-container" style="margin-bottom: 30px;">
                <div class="video-wrapper">
                    <video width="100%" height="auto" controls>
                        <source src="./video/5_diff_opt.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </div>
                <div style="padding: 15px;">
                    <p class="result-description">
                        The visualization of MASH optimization process and the differences of representability between varying numbers of anchors.
                    </p>
                </div>
            </div>
        </div>

        <!-- 内部结构 -->
        <div class="content-section">
            <h2>Inner Structure</h2>
            <div align="center" style="margin-top: 30px; margin-bottom: 30px;">
                <img src="./images/inner_structure.png" style="max-width: 880px; width: 100%;" alt="MASH内部结构">
            </div>
            <p class="result-description" style="margin-top: 15px; color: #333;">
                The inner structure of MASH reveals how the representation encodes 3D shape information through a network of anchor points. Each anchor point captures local geometry using spherical distance functions, while the masking mechanism ensures that only relevant surface regions are represented. This hierarchical organization allows MASH to efficiently model complex shapes with varying levels of detail, enabling accurate reconstruction and generation of 3D objects with diverse topologies.
            </p>
        </div>

        <!-- 结果展示 -->
        <div class="content-section">
            <h2>Results</h2>
            <div class="results-grid">
                <div class="result-item">
                    <img src="./images/eval-offline-compare-000001-v6.png" class="result-image" alt="Figure 2">
                    <div class="result-content">
                        <p class="result-description">
                            <strong>Figure 2:</strong> Qualitative comparison with offline CAD recomposition baselines.
                        </p>
                    </div>
                </div>
                <div class="result-item">
                    <img src="./images/eval-online-compare-065300-v5.png" class="result-image" alt="Figure 3">
                    <div class="result-content">
                        <p class="result-description">
                            <strong>Figure 3:</strong> Qualitative comparison with online CAD recomposition baselines.
                        </p>
                    </div>
                </div>
                <div class="result-item">
                    <img src="./images/eval-visual-result-v7.png" class="result-image" alt="Figure 4">
                    <div class="result-content">
                        <p class="result-description">
                            <strong>Figure 4:</strong> Example results generated by our online scene CAD recomposition method.
                        </p>
                    </div>
                </div>
            </div>
        </div>

        <!-- 致谢 -->
        <div class="content-section">
            <h2>Acknowledgments</h2>
            <p class="result-description">
                We thank the anonymous reviewers for their valuable comments. This work is supported by the
                National Key R&D Program of China (2022YFB3303400),
                National Natural Science Foundation of China (62025207, 62322207),
                Shenzhen Science and Technology Program (RCYX20210609103121030),
                and GD Natural Science Foundation (2021B1515020085).
            </p>
        </div>

        <!-- BibTeX -->
        <div class="content-section">
            <h2>BibTeX</h2>
            <pre class="result-description">
@article{Li-2023-AutoScan2CAD,
    title = {Online Scene CAD Recomposition via Autonomous Scanning},
    author = {Changhao Li, Junfu Guo, Ruizhen Hu, Ligang Liu},
    journal = {ACM Transactions on Graphics (SIGGRAPH Asia 2023)},
    volume = {42},
    number = {6},
    pages = {Article 250: 1-16},
    year = {2023}
}</pre>
        </div>
    </div>

    <footer>
        <p>&copy; 2024 MASH Project</p>
        <a href="https://github.com/565353780/ma-sh" class="github-link">View on GitHub</a>
    </footer>
</body>

</html>